{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "fda72a13-e5e6-4224-9885-e3e99d95e73f",
      "metadata": {
        "id": "fda72a13-e5e6-4224-9885-e3e99d95e73f"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/UNSW-COMP9414/Tutorials/blob/main/Week07/COMP9414-Week07-Neural-Networks.ipynb)\n",
        "\n",
        "# Training and Assessing Neural Networks with Keras\n",
        "\n",
        "**COMP9414 W07 Tutorial**\n",
        "\n",
        "- Instructor: Gustavo Batista\n",
        "- School of Computer Science and Engineering, UNSW Sydney\n",
        "- Notebook designed by Gustavo Batista\n",
        "- Last Update 2nd October 2024"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "253e470a-52a9-4fca-b17a-fedd35efbcc5",
      "metadata": {
        "id": "253e470a-52a9-4fca-b17a-fedd35efbcc5"
      },
      "source": [
        "In this week's tutorial, we will train and assess a multi-layer perceptron, a type of \"deep\" neural network architecture. We will start with the well-known benchmark dataset, MNIST, with images of single handwritten digits (0-9).\n",
        "\n",
        "We will use Keras as our main framework for implementing deep learning models. Keras is now part of the TensorFlow framework and provides a simple library for learning these models."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4ae70bb-242e-4a62-b0de-c45c05743955",
      "metadata": {
        "id": "a4ae70bb-242e-4a62-b0de-c45c05743955"
      },
      "source": [
        "## Technical prerequisites\n",
        "\n",
        "You will need the following packages installed to run this notebook:\n",
        "\n",
        "1. Numpy\n",
        "2. Matplotlib\n",
        "3. Scikit-learn\n",
        "4. Tensorflow\n",
        "\n",
        "The first three libraries are often found in most installations. If they are not installed on your system, you can install them using the `pip` or `conda` commands.\n",
        "\n",
        "TensorFlow usually requires an older Python version. If you have installation conflicts, we suggest creating an environment for TensorFlow with a compatible Python version. Alternatively, you can run this notebook on Google Colab (see link in the first cell), which has the Tensorflow library installed. You will need to install keras-tuner, though."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "5f75e0c0-45f2-4aab-9ba0-fa2724c38d3f",
      "metadata": {
        "id": "5f75e0c0-45f2-4aab-9ba0-fa2724c38d3f",
        "outputId": "7e515567-35e4-4354-a566-2c988be0a55c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'keras_tuner'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-e7651f2bde59>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Uncomment the next line if you need to install the Keras Tuner library\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# !pip install keras-tuner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras_tuner\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHyperModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras_tuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtuners\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomSearch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras_tuner'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "# NumPy and matplotlib libraries for numerical computation and plotting\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Tensorflow/keras libraries for deep-learning models\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, Dense, Flatten, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
        "\n",
        "# Keras Tuner libraries for hyperparameter tuning\n",
        "# Uncomment the next line if you need to install the Keras Tuner library\n",
        "# !pip install keras-tuner\n",
        "from keras_tuner import HyperModel\n",
        "from keras_tuner.tuners import RandomSearch\n",
        "\n",
        "# Scikit-learn libraries for model assessment\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9366a01-0b3c-4101-8174-f208a46b30f8",
      "metadata": {
        "id": "b9366a01-0b3c-4101-8174-f208a46b30f8"
      },
      "source": [
        "The following line will tell you how many CPUs and GPUs your system has. If you have a GPU, you can expect a speed-up in model training time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c418a5e8-7ea8-49c0-bec2-88cd69cb9b87",
      "metadata": {
        "id": "c418a5e8-7ea8-49c0-bec2-88cd69cb9b87"
      },
      "outputs": [],
      "source": [
        "print(\"Number CPUs Available: \", len(tf.config.list_physical_devices('CPU')))\n",
        "print(\"Number GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35f4b9d3-d231-4917-ae52-1a0347966928",
      "metadata": {
        "id": "35f4b9d3-d231-4917-ae52-1a0347966928"
      },
      "source": [
        "## The MNIST dataset\n",
        "\n",
        "We will train a simple, fully connected neural network using Keras to classify handwritten digits from the MNIST dataset.\n",
        "\n",
        "The MNIST dataset contains 70,000 grayscale images of handwritten digits (0-9), each of size 28x28 pixels. This dataset is very popular for benchmarking Machine Learning models. It is even available as part of the TensorFlow installation.\n",
        "\n",
        "We can use the following command to load the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f844e41-77e3-473d-b7b8-a614c4d04b84",
      "metadata": {
        "id": "8f844e41-77e3-473d-b7b8-a614c4d04b84"
      },
      "outputs": [],
      "source": [
        "# Load the dataset\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b30efb0a-322a-47bc-b94a-d3ec59a14035",
      "metadata": {
        "id": "b30efb0a-322a-47bc-b94a-d3ec59a14035"
      },
      "source": [
        "MNIST comes with a standard splitting of training and test sets. The training set should be used for model fitting and hyperparameter search, and the test set should be used exclusively for model evaluation. Using the test set for any other task is a methodological mistake.\n",
        "\n",
        "We have the following data splits:\n",
        "\n",
        "1. `X_train`: the training data we will use to fit our model parameters.\n",
        "2. `y_train`: the associated labels for each training case.\n",
        "3. `X_test`: the test data we will use to assess the model performance.\n",
        "4. `y_test`: the associated labels for each test instance.\n",
        "\n",
        "The MNIST is a relatively large dataset. It has 60,000 training images and 10,000 test images, as we can see below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "445b8e89-9af1-46b4-aa12-5cb3da9e554a",
      "metadata": {
        "id": "445b8e89-9af1-46b4-aa12-5cb3da9e554a"
      },
      "outputs": [],
      "source": [
        "print(\"MNIST size (number of images, number of image lines, number of image columns)\")\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(\"These are the labels, each training or testing image has an associated label (0-9)\")\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32155cf8-3c0d-49ca-8fe5-6783ab1b3567",
      "metadata": {
        "id": "32155cf8-3c0d-49ca-8fe5-6783ab1b3567"
      },
      "source": [
        "Let's visualise some digits to understand how complex this problem is. The following cell plots the first six digits in the training set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "774d7d0a-56fc-4efe-8fef-43118114c873",
      "metadata": {
        "scrolled": true,
        "id": "774d7d0a-56fc-4efe-8fef-43118114c873"
      },
      "outputs": [],
      "source": [
        "# Visualise the first six digits in the training set\n",
        "plt.figure(figsize=(10, 4))\n",
        "for i in range(6):\n",
        "    plt.subplot(2, 3, i+1)\n",
        "    plt.imshow(X_train[i], cmap='gray')\n",
        "    plt.title(f'Label: {y_train[i]}')\n",
        "    plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5485cb31-b3f9-47c2-a776-e2bde0742883",
      "metadata": {
        "id": "5485cb31-b3f9-47c2-a776-e2bde0742883"
      },
      "source": [
        "We can also visualise some images from the same digit to get an idea of the variability in each class. Feel free to change the first line to see images of the other digits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92a3f9fd-cfa4-490d-b45c-b551a6e56c36",
      "metadata": {
        "id": "92a3f9fd-cfa4-490d-b45c-b551a6e56c36"
      },
      "outputs": [],
      "source": [
        "# Visualise the first six 'five' digits in the training set\n",
        "indices = np.where(y_train == 5)[0]  # Find the indices of the images for class 5\n",
        "plt.figure(figsize=(10, 4))\n",
        "for i in range(6):\n",
        "    plt.subplot(2, 3, i+1)\n",
        "    plt.imshow(X_train[indices[i]], cmap='gray')\n",
        "    plt.title(f'Label: {y_train[indices[i]]}')\n",
        "    plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09c59ac9-8abd-4635-bdd4-87e792bf1c58",
      "metadata": {
        "id": "09c59ac9-8abd-4635-bdd4-87e792bf1c58"
      },
      "source": [
        "Before we conclude this section about the dataset, we will make two simple pre-processing:\n",
        "\n",
        "1. Each pixel is represented by a number between 0 and 255. We will normalize the pixels to be numbers between 0 and 1, which will facilitate training.\n",
        "2. We will convert the class numbers into a one-hot encoding. One-hot encodings represent the output as a vector. Each entry represents one class, and the vector will have zeros for all entries but one that represents the class.\n",
        "\n",
        "These are examples of one-hot encodings:\n",
        "1. The digit 0 is represented as [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        "2. The digit 5 is represented as [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
        "3. The digit 9 is represented as [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2bab936c-085f-4222-aa07-60005dc08dcc",
      "metadata": {
        "id": "2bab936c-085f-4222-aa07-60005dc08dcc"
      },
      "outputs": [],
      "source": [
        "# Normalise the data\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "y_train_one_hot = to_categorical(y_train, 10)\n",
        "y_test_one_hot = to_categorical(y_test, 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95634aee-1201-433a-8576-6f8975b834f5",
      "metadata": {
        "id": "95634aee-1201-433a-8576-6f8975b834f5"
      },
      "source": [
        "## Defining a model Neural Network model with Keras\n",
        "\n",
        "Keras makes it very simple to create a deep-learning model. The process has three main steps:\n",
        "\n",
        "1. Model definition: We declare the model architecture, specifying the properties of each layer, such as the number of units and activation function.\n",
        "2. Model compilation: This step prepares the model for training, specifying aspects such as the optimizer, the loss function, and the metrics to be monitored during training.\n",
        "3. Model fitting: This step fits the model to the dataset. In this step, we need to specify the training data, number of epochs, batch size, and validation data.\n",
        "\n",
        "Let's define our first model with the following architecture:\n",
        "\n",
        "1. 784 input units that correspond to the number of pixels in the image ($28 \\times 28$). In this case, each normalised pixel colour will be one input to the model.\n",
        "2. 64 hidden units. This design decision is difficult to justify, as the hidden units should be proportional to the data's \"complexity.\" We will play with this hyperparameter later.\n",
        "3. 10 output units. This is the number of classes, and each unit corresponds to one digit (class) in the one-hot encoding.\n",
        "\n",
        "The following figure illustrates the neural network architecture.\n",
        "\n",
        "![First architecture](https://github.com/UNSW-COMP9414/Tutorials/blob/main/Week07/img/first_model.png?raw=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10a14dee-0641-42d3-827b-751fbc339eae",
      "metadata": {
        "id": "10a14dee-0641-42d3-827b-751fbc339eae"
      },
      "outputs": [],
      "source": [
        "model = Sequential([\n",
        "    Input(shape=(28, 28)),                  # Input is a 28x28 image\n",
        "    Flatten(),                              # Flatten the 28x28 input images into a 784-length vector\n",
        "    Dense(64, activation='relu'),           # Hidden layer with 64 neurons and ReLU activation\n",
        "    Dense(10, activation='softmax')         # Output layer with 10 neurons (one for each digit)\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c26b55f0-7aca-4add-9c43-6cd3afb3b19a",
      "metadata": {
        "id": "c26b55f0-7aca-4add-9c43-6cd3afb3b19a"
      },
      "source": [
        "There are several observations for the previous cell:\n",
        "\n",
        "1. The sequential model specifies that we are creating a neural network with a sequence of layers. It is a sequence in that the input layer feeds the hidden layer that feeds the output layer.\n",
        "2. The input is $28 \\times 28$ images, but the neural network has 784 input units. Therefore, the `Flatten` statement \"flats\" the matrix into a vector.\n",
        "3. We follow up with two additional dense layers. The first is a hidden layer with ReLU activation, and the second is the output layer with softmax activation.\n",
        "\n",
        "Now, we are ready to compile our model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5cc53e5-a5ad-4129-8f87-772d6deca063",
      "metadata": {
        "id": "f5cc53e5-a5ad-4129-8f87-772d6deca063"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "689bf73c-2c07-4d1e-a99e-2e12ac44a0b2",
      "metadata": {
        "id": "689bf73c-2c07-4d1e-a99e-2e12ac44a0b2"
      },
      "source": [
        "Notice that in this compilation step, we specified Adam as the optimiser, cross-entropy as the loss function, and accuracy as the performance measure for later model assessment.\n",
        "\n",
        "Finally, we can train the model for 10 epochs with a batch size of 32 images. This will take a while to complete."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8164dcfd-1dfd-4863-b45e-b7e986012249",
      "metadata": {
        "id": "8164dcfd-1dfd-4863-b45e-b7e986012249"
      },
      "outputs": [],
      "source": [
        "history = model.fit(X_train, y_train_one_hot, epochs=10, validation_split=0.2, batch_size=32)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25fbb9eb-fc71-4af4-afa2-6166d5f58937",
      "metadata": {
        "id": "25fbb9eb-fc71-4af4-afa2-6166d5f58937"
      },
      "source": [
        "We use 20% of the training set as a validation set. This validation set helps us to understand if the model is overfitting the training data. The following figure plots the training and validation loss and accuracy during the model training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e5d0408-6449-476e-8c26-a8589d3d084d",
      "metadata": {
        "id": "2e5d0408-6449-476e-8c26-a8589d3d084d"
      },
      "outputs": [],
      "source": [
        "# Plot training & validation accuracy values\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c64cb8af-0a83-462a-bb8f-5e0323a58cea",
      "metadata": {
        "id": "c64cb8af-0a83-462a-bb8f-5e0323a58cea"
      },
      "source": [
        "Finally, we can assess the model's performance by measuring its accuracy in the test set. The test set is a partition of the data used **only** for model assessment. It should never be used for model fitting or hyperparameter search."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "537b09e0-0e4d-4416-8f52-5b0ae0bb785f",
      "metadata": {
        "id": "537b09e0-0e4d-4416-8f52-5b0ae0bb785f"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model on test data\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test_one_hot)\n",
        "print(f'Test accuracy: {test_accuracy:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b6cd16b-e656-4b80-9c6c-4de704c6a370",
      "metadata": {
        "id": "5b6cd16b-e656-4b80-9c6c-4de704c6a370"
      },
      "source": [
        "Nice! We created a model with 97.31% accuracy! This is pretty accurate and may indicate that the MNIST dataset is not very difficult.\n",
        "\n",
        "Our model makes less than 3% of mistakes in a 10,000-sample test set. Therefore, it misclassifies around 260 images. The classifier's accuracy/error gives us no information about whether we perform equally well in all classes or whether some are more difficult.\n",
        "\n",
        "In the next cell, we will exercise to plot the confusion matrix. This will tell us which classes are the most misclassified and how they are misclassified among them.\n",
        "\n",
        "### Exercise\n",
        "\n",
        "A confusion matrix is a performance evaluation tool for classification models. It provides a visual summary of the modelâ€™s predictions compared to the actual values. The confusion matrix is a table. Each row represents the instances of an actual class, while each column represents the instances of a predicted class, making it easy to see which classes are most often confused with each other. A perfect model would have non-zero values only along the diagonal of the confusion matrix, indicating that all predictions are correct.\n",
        "\n",
        "The scikit-learn library has the [``confusion_matrix``](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html) and [``ConfusionMatrixDisplay``](https://scikit-learn.org/1.5/modules/generated/sklearn.metrics.ConfusionMatrixDisplay.html) functions that compute and plot confusion matrices (see the links for the official documentation).\n",
        "\n",
        "We will use the method [``model.predict``](https://keras.io/api/models/model_training_apis/) to return the classification for the test cases. The predictions come in as one-hot encoding, and we will need to convert them to numbers between 0 and 9 using the [``np.argmax``](https://numpy.org/doc/2.0/reference/generated/numpy.argmax.html) method.\n",
        "\n",
        "The next cell will compute and plot the confusion matrix. We have done most of the work for you!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e8fb794-8497-4bfe-872f-02e755ec0882",
      "metadata": {
        "id": "6e8fb794-8497-4bfe-872f-02e755ec0882"
      },
      "outputs": [],
      "source": [
        "# Predict on the test set\n",
        "y_pred = ...                                         # TODO, call model.predict to predict the labels for X_test\n",
        "y_pred_classes = ...                                 # TODO, call np.argmax to transform the predicted class probabilities (y_pred) into class 0-9 predictions\n",
        "\n",
        "# Create the confusion matrix\n",
        "cm = ...                                             # TODO, call confusion_matrix and inform the actual labels (y_test) and the predicted labels (y_pred_classes)\n",
        "\n",
        "# Display the confusion matrix\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=np.arange(10))\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "844f7ef7-0505-4b33-acc8-a91b6755619b",
      "metadata": {
        "id": "844f7ef7-0505-4b33-acc8-a91b6755619b"
      },
      "source": [
        "## Qualitative model assessment\n",
        "\n",
        "So far, we have assessed our model quantitatively. In the next part, we will conduct a more qualitative assessment. In a qualitative assessment, we examine the misclassified images. We aim to understand if the model is making silly mistakes or if the data has difficult images. For instance, the confusion matrix has shown us that the digit \"9\" is often misclassified, particularly with the digit 4. The qualitative analysis will help us to understand if these two digits are truly similar or if the model still has room for improvement.\n",
        "\n",
        "### Exercise\n",
        "\n",
        "Let's plot 100 incorrect predictions to better understand the classifier's performance. We have done most of the heavy lifting for you; you just need to complete one line of code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56084707-f2c1-4517-8709-1a3791a839a6",
      "metadata": {
        "id": "56084707-f2c1-4517-8709-1a3791a839a6"
      },
      "outputs": [],
      "source": [
        "# Find misclassified images\n",
        "misclassified_indices = ...                                         # TODO. Use np.where to find the indices of the images where y_pred_classes differs from y_test\n",
        "\n",
        "# Plot a 10x10 grid of misclassified images\n",
        "num_images = 100  # Number of misclassified images to display\n",
        "plt.figure(figsize=(15, 15))\n",
        "for i, index in enumerate(misclassified_indices[:num_images]):\n",
        "    plt.subplot(10, 10, i + 1)\n",
        "    plt.imshow(X_test[index], cmap='gray')\n",
        "    plt.title(f\"True: {y_test[index]}\\nPred: {y_pred_classes[index]}\")\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc5498ab-2300-420b-be5b-3e6970808b25",
      "metadata": {
        "id": "cc5498ab-2300-420b-be5b-3e6970808b25"
      },
      "source": [
        "## Hyperparameter search\n",
        "\n",
        "Now that you understand how to create and assess your models let's see if we can improve the deep learning models' performance for the MNIST dataset.\n",
        "\n",
        "Deep learning models have several hyperparameters that can influence their performance. Here are some ideas:\n",
        "\n",
        "1. Model architecture: We could make the model architecture smaller or bigger and see if it can improve performance.\n",
        "2. We can train the models for a longer period.\n",
        "3. We can use a different optimiser, SGD, instead of ADAM.\n",
        "\n",
        "Unfortunately, testing all possible combinations of hyperparameters is very time-consuming. However, we can assess some of these ideas against our initial model."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2aa732b8-9700-4f90-aa9f-f9d75826b45d",
      "metadata": {
        "id": "2aa732b8-9700-4f90-aa9f-f9d75826b45d"
      },
      "source": [
        "### Exercise\n",
        "\n",
        "Define a new architecture with 128 hidden units instead of 64. Does this change improve accuracy?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7789b17-9ced-4cb6-9507-549eb69fd36c",
      "metadata": {
        "id": "c7789b17-9ced-4cb6-9507-549eb69fd36c"
      },
      "outputs": [],
      "source": [
        "model = Sequential([\n",
        "...                            # TODO\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, y_train_one_hot, epochs=10, validation_split=0.2, batch_size=32)\n",
        "\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test_one_hot)\n",
        "print(f'Test accuracy: {test_accuracy:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5094931-c4c1-4c9b-8c5f-2a6dd6520f1d",
      "metadata": {
        "id": "d5094931-c4c1-4c9b-8c5f-2a6dd6520f1d"
      },
      "source": [
        "### Exercise\n",
        "\n",
        "Define a new architecture with no hidden layer. Does this change improve accuracy?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c80ecbe1-b752-4a8c-a826-916c0f4c3063",
      "metadata": {
        "id": "c80ecbe1-b752-4a8c-a826-916c0f4c3063"
      },
      "outputs": [],
      "source": [
        "model = Sequential([\n",
        "...                            # TODO\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, y_train_one_hot, epochs=10, validation_split=0.2, batch_size=32)\n",
        "\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test_one_hot)\n",
        "print(f'Test accuracy: {test_accuracy:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7eae7c2a-10c4-40df-aa72-5f3651d2e1e5",
      "metadata": {
        "id": "7eae7c2a-10c4-40df-aa72-5f3651d2e1e5"
      },
      "source": [
        "### Exercise\n",
        "\n",
        "Train the original model for 30 epochs. Does this change improve accuracy?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb26b7e7-5be2-42c7-8b15-8fef4b1ac89d",
      "metadata": {
        "id": "cb26b7e7-5be2-42c7-8b15-8fef4b1ac89d"
      },
      "outputs": [],
      "source": [
        "model = Sequential([\n",
        "    Input(shape=(28, 28)),                  # Input is a 28x28 image\n",
        "    Flatten(),                              # Flatten the 28x28 input images into a 784-length vector\n",
        "    Dense(64, activation='relu'),           # Hidden layer with 64 neurons and ReLU activation\n",
        "    Dense(10, activation='softmax')         # Output layer with 10 neurons (one for each digit)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(...)                              # TODO\n",
        "\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test_one_hot)\n",
        "print(f'Test accuracy: {test_accuracy:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78c31625-01a6-4549-a130-9bb59fb07f3c",
      "metadata": {
        "id": "78c31625-01a6-4549-a130-9bb59fb07f3c"
      },
      "source": [
        "Well, it seems that only increasing the model capacity improved the accuracy by a small fraction. You can try other ideas, but MNIST is a relatively easy dataset, and it becomes hard to improve when we have close to 100% accuracy.\n",
        "\n",
        "In the next part, we will use Keras Tuner, a more systematic approach for hyperparameter optimisation."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "230806e4-02d8-42b3-85a5-f53ef6e55272",
      "metadata": {
        "id": "230806e4-02d8-42b3-85a5-f53ef6e55272"
      },
      "source": [
        "## Parameter tuning as a search procedure with Keras Tuner\n",
        "\n",
        "We like to think of AI as a search problem. We learned that fitting a neural network parameter is a search guided by the loss gradients, in which we look for the parameter combination that minimises the loss.\n",
        "\n",
        "We can use a similar idea and think of hyperparameters as a search problem. In this case, we can use a validation set error or accuracy and try different combinations of hyperparameters. Unfortunately, this is a computationally expensive procedure, and neural networks have many hyperparameters to evaluate.\n",
        "\n",
        "We can use Keras Tuner to automate the search for hyperparameters. Let's start with a simpler experiment. Motivated by the idea that the number of units in the hidden layer might be a relevant hyperparameter, we will use the Keras Tuner to try a few possibilities.\n",
        "\n",
        "The main idea is to define a HyperModel. A HyperModel allows us to specify a set of models. In our case, these models will have different numbers of hidden units from 32 to 256 with increments of 32."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "010b5a0e-5f7e-4ef7-9976-2607c808ce8c",
      "metadata": {
        "id": "010b5a0e-5f7e-4ef7-9976-2607c808ce8c"
      },
      "outputs": [],
      "source": [
        "class FirstHyperModel(HyperModel):\n",
        "    def build(self, hp):\n",
        "        model = Sequential()\n",
        "        model.add(Input(shape=(28, 28)))\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(units=hp.Int('units', min_value=32, max_value=256, step=32), activation='relu'))\n",
        "        model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "        return model\n",
        "\n",
        "tuner = RandomSearch(\n",
        "    FirstHyperModel(),\n",
        "    objective='val_accuracy',\n",
        "    max_trials=5,                    # Number of different architectures to try\n",
        "    executions_per_trial=3,          # Averaging over 3 different runs per architecture\n",
        "    directory='log_results',         # Folder to save the results\n",
        "    project_name='mnist_tuning'\n",
        ")\n",
        "\n",
        "tuner.search(X_train, y_train_one_hot, epochs=10, validation_split=0.2)\n",
        "tuner.results_summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4497fec0-977c-4f63-b83f-5ba381757b19",
      "metadata": {
        "id": "4497fec0-977c-4f63-b83f-5ba381757b19"
      },
      "source": [
        "If you want to assess the best model in the test set, then you need to retrive it first, using the following code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "360227c1-d4a1-427c-b2c2-5eaeb2e92faa",
      "metadata": {
        "id": "360227c1-d4a1-427c-b2c2-5eaeb2e92faa"
      },
      "outputs": [],
      "source": [
        "# Retrieve the best model\n",
        "best_model = tuner.get_best_models(num_models=1)[0]\n",
        "\n",
        "# Evaluate the best model on the independent test set\n",
        "test_loss, test_accuracy = best_model.evaluate(X_test, y_test_one_hot)\n",
        "\n",
        "# Print the test accuracy\n",
        "print(f'Test accuracy: {test_accuracy:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b5f1d7d-7cd5-49ac-8d5d-72a30c30f6b1",
      "metadata": {
        "id": "4b5f1d7d-7cd5-49ac-8d5d-72a30c30f6b1"
      },
      "source": [
        "### Exercise\n",
        "\n",
        "Let's try to search for more hyperparameters now. Let's try the following:\n",
        "- One, two or three hidden layers\n",
        "- 32 to 512 hidden units per layer in increments of 32 units\n",
        "- ReLu, tanh or sigmoid activation functions\n",
        "- Adam, SGD or RMSProp optimisers\n",
        "\n",
        "This will take a while to run. We will set ``max_trials=20``, so we will not explore all combinations of hyperparameter values. If you have a more powerful computer, feel free to increase this number and explore the combinations better.\n",
        "\n",
        "We will run this as an exercise. We have done most of the work for you but must complete a few missing parts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf1711af-918b-4518-84ab-835de7ae6015",
      "metadata": {
        "id": "bf1711af-918b-4518-84ab-835de7ae6015"
      },
      "outputs": [],
      "source": [
        "class SecondHyperModel(HyperModel):\n",
        "    def build(self, hp):\n",
        "        model = ...                                                                                         # TODO. Define the model input as in the previous first model\n",
        "        model.add(...)\n",
        "        model.add(...)\n",
        "\n",
        "        # Tune the number of hidden layers (between 1 and 3)\n",
        "        for i in range(hp.Int('num_layers', 1, 3)):                                                         # This is the number of hidden layers\n",
        "            # Tune the number of units in each layer\n",
        "            model.add(Dense(units=hp.Int('units_' + str(i), min_value=..., max_value=..., step=...),        # TODO\n",
        "                            activation=hp.Choice('activation_' + str(i), ['relu', 'tanh', 'sigmoid'])))     # These are the activation functions\n",
        "\n",
        "        # Output Layer                                                                                      # TODO. Define the model output as in the first model\n",
        "        model.add(...)\n",
        "\n",
        "        # Tune the learning rate for the optimizer\n",
        "        optimizer = hp.Choice('optimizer', ['adam', 'sgd', 'rmsprop'])                                      # These are the optimisers\n",
        "        if optimizer == 'adam':\n",
        "            opt = Adam(learning_rate=hp.Float('learning_rate', 1e-4, 1e-2, sampling='log'))\n",
        "        elif optimizer == 'sgd':\n",
        "            opt = SGD(learning_rate=hp.Float('learning_rate', 1e-4, 1e-2, sampling='log'))\n",
        "        else:\n",
        "            opt = RMSprop(learning_rate=hp.Float('learning_rate', 1e-4, 1e-2, sampling='log'))\n",
        "\n",
        "        model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "        return model\n",
        "\n",
        "# Instantiate the tuner\n",
        "tuner = RandomSearch(\n",
        "    SecondHyperModel(),\n",
        "    objective='val_accuracy',\n",
        "    max_trials=20,                   # Number of different models to try\n",
        "    executions_per_trial=3,          # Averaging results from 3 runs\n",
        "    directory='log_results',         # Folder to save the results\n",
        "    project_name='mnist_tuning_large'\n",
        ")\n",
        "\n",
        "# Perform the search\n",
        "tuner.search(X_train, y_train_one_hot, epochs=10, validation_split=0.2)\n",
        "\n",
        "# Retrieve the best hyperparameters\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "print(f\"Best number of layers: {best_hps.get('num_layers')}\")\n",
        "print(f\"Best number of units in first layer: {best_hps.get('units_0')}\")\n",
        "print(f\"Best optimizer: {best_hps.get('optimizer')}\")\n",
        "print(f\"Best learning rate: {best_hps.get('learning_rate')}\")\n",
        "\n",
        "# Retrieve the best model\n",
        "best_model = tuner.get_best_models(num_models=1)[0]\n",
        "\n",
        "# Evaluate the best model on the independent test set\n",
        "test_loss, test_accuracy = best_model.evaluate(X_test, y_test_one_hot)\n",
        "\n",
        "# Print the test accuracy\n",
        "print(f'Test accuracy: {test_accuracy:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d680eaa1-35b4-4328-ad82-13668e967fa8",
      "metadata": {
        "id": "d680eaa1-35b4-4328-ad82-13668e967fa8"
      },
      "source": [
        "# Conclusion\n",
        "\n",
        "Today, we have learned how to implement and evaluate deep learning models using Keras. In the next tutorial, we will look at decision trees and ensembles of these models, known as random forests. These are powerful models to learn from tabular datasets."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}